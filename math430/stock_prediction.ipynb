{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (0.13.0)\n",
      "Collecting ta\n",
      "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from ta) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from pandas->ta) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from pandas->ta) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
      "Building wheels for collected packages: ta\n",
      "  Building wheel for ta (setup.py): started\n",
      "  Building wheel for ta (setup.py): finished with status 'done'\n",
      "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29497 sha256=47eb076df59bfa0da80f13604f737c29757409ece27abd5ac5f03c40e11da203\n",
      "  Stored in directory: c:\\users\\john\\appdata\\local\\pip\\cache\\wheels\\5c\\a1\\5f\\c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
      "Successfully built ta\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn  ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "import ta\n",
    "\n",
    "# Load data\n",
    "file_path = \"nq024.csv\"  # Replace with your actual file path\n",
    "data = pd.read_csv(file_path, parse_dates=[\"Time\"], index_col=\"Time\")\n",
    "data = data[::-1]  # Ensure chronological order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Last' price as 'Close' for simplicity\n",
    "data[\"Close\"] = data[\"Last\"]\n",
    "df_close = data[\"Close\"]\n",
    "\n",
    "# Add technical indicators\n",
    "data[\"SMA_10\"] = ta.trend.sma_indicator(data[\"Close\"], window=10)\n",
    "data[\"SMA_30\"] = ta.trend.sma_indicator(data[\"Close\"], window=30)\n",
    "data[\"RSI\"] = ta.momentum.rsi(data[\"Close\"], window=14)\n",
    "bb = ta.volatility.BollingerBands(data[\"Close\"], window=20)\n",
    "data[\"BB_upper\"] = bb.bollinger_hband()\n",
    "data[\"BB_middle\"] = bb.bollinger_mavg()\n",
    "data[\"BB_lower\"] = bb.bollinger_lband()\n",
    "\n",
    "# Add MACD and Signal Line\n",
    "macd = ta.trend.macd(data[\"Close\"])\n",
    "macd_signal = ta.trend.macd_signal(data[\"Close\"])\n",
    "data[\"MACD\"] = macd\n",
    "data[\"MACD_Signal\"] = macd_signal\n",
    "\n",
    "# Add ATR\n",
    "data[\"ATR\"] = ta.volatility.average_true_range(data[\"High\"], data[\"Low\"], data[\"Close\"])\n",
    "\n",
    "# Add lagged returns\n",
    "data[\"Return\"] = data[\"Close\"].pct_change()\n",
    "for lag in range(1, 6):\n",
    "    data[f\"Lag_{lag}\"] = data[\"Return\"].shift(lag)\n",
    "\n",
    "# Add volume indicators (calculate SMA manually)\n",
    "data[\"Volume_SMA_10\"] = data[\"Volume\"].rolling(window=10).mean()\n",
    "data[\"Volume_SMA_30\"] = data[\"Volume\"].rolling(window=30).mean()\n",
    "\n",
    "# Transform data\n",
    "df_close_log = np.log(df_close)\n",
    "df_close_tf = np.sqrt(df_close_log)\n",
    "df_close_shift = df_close_tf - df_close_tf.shift()\n",
    "df_close_shift.dropna(inplace=True)\n",
    "\n",
    "# Combine technical indicators with transformed data\n",
    "data[\"Close_shift\"] = df_close_shift\n",
    "features = [\n",
    "    \"SMA_10\",\n",
    "    \"SMA_30\",\n",
    "    \"RSI\",\n",
    "    \"BB_upper\",\n",
    "    \"BB_middle\",\n",
    "    \"BB_lower\",\n",
    "    \"MACD\",\n",
    "    \"MACD_Signal\",\n",
    "    \"ATR\",\n",
    "    \"Lag_1\",\n",
    "    \"Lag_2\",\n",
    "    \"Lag_3\",\n",
    "    \"Lag_4\",\n",
    "    \"Lag_5\",\n",
    "    \"Volume_SMA_10\",\n",
    "    \"Volume_SMA_30\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "data[features] = imputer.fit_transform(data[features])\n",
    "\n",
    "# Normalize features\n",
    "data[features] = (data[features] - data[features].mean()) / data[features].std()\n",
    "\n",
    "# Create binary target variable (predicting the direction)\n",
    "data[\"Target\"] = (data[\"Close_shift\"] > df_close_shift.mean()).astype(int)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X = data[features]\n",
    "y = data[\"Target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for RandomForest\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "grid_search_rf.fit(X_train_smote, y_train_smote)\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best parameters for RandomForest: \", best_params_rf)\n",
    "\n",
    "# Train the Random Forest model with the best parameters and class weights\n",
    "rf_model = RandomForestClassifier(\n",
    "    **best_params_rf, class_weight=\"balanced\", random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Train Gradient Boosting Model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Ensemble model with Voting Classifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[(\"rf\", rf_model), (\"gb\", gb_model)], voting=\"soft\"\n",
    ")\n",
    "ensemble_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot feature importance for RandomForest\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances (RandomForest)\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Predicting next 4 or 8 hours\n",
    "def predict_next_hours(model, data, features, imputer, n_hours=8):\n",
    "    last_data = data[features].tail(1)\n",
    "    last_data = pd.DataFrame(\n",
    "        imputer.transform(last_data), columns=features\n",
    "    )  # Ensure no NaN values in the last_data\n",
    "    predictions = []\n",
    "    last_close = data[\"Close\"].iloc[-1]\n",
    "    last_timestamp = data.index[-1]\n",
    "\n",
    "    for _ in range(n_hours):\n",
    "        # Get the prediction probabilities\n",
    "        prediction_prob = model.predict_proba(last_data)[0]\n",
    "        direction = np.argmax(prediction_prob)\n",
    "\n",
    "        # Simulate the price movement with uncertainty\n",
    "        if direction == 1:\n",
    "            # Predicted to go up\n",
    "            price_change = np.random.normal(\n",
    "                loc=0.002, scale=0.001\n",
    "            )  # mean positive change\n",
    "        else:\n",
    "            # Predicted to go down\n",
    "            price_change = np.random.normal(\n",
    "                loc=-0.002, scale=0.001\n",
    "            )  # mean negative change\n",
    "\n",
    "        predicted_price = last_close * (1 + price_change)\n",
    "        low_bound = predicted_price * (1 - 0.002)\n",
    "        high_bound = predicted_price * (1 + 0.002)\n",
    "\n",
    "        last_timestamp += pd.Timedelta(hours=1)\n",
    "        predictions.append(\n",
    "            (last_timestamp, direction, predicted_price, low_bound, high_bound)\n",
    "        )\n",
    "\n",
    "        # Update last_data for next prediction\n",
    "        last_data = last_data.shift(-1, axis=1)\n",
    "        last_data.iloc[0, -1] = (\n",
    "            predicted_price  # Use the predicted price for the next iteration\n",
    "        )\n",
    "        last_data = pd.DataFrame(\n",
    "            imputer.transform(last_data), columns=features\n",
    "        )  # Ensure no NaN values after update\n",
    "\n",
    "        last_close = predicted_price\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Ensure the imputer is fitted\n",
    "imputer.fit(X)\n",
    "\n",
    "# Predict next 8 hours\n",
    "predicted_data = predict_next_hours(ensemble_model, data, features, imputer, n_hours=8)\n",
    "\n",
    "# Print last closing price and predicted prices with timestamps and directions\n",
    "print(\"Last closing price:\", data[\"Close\"].iloc[-1])\n",
    "print(\"Predicted prices for the next 8 hours:\")\n",
    "for timestamp, direction, price, low, high in predicted_data:\n",
    "    direction_str = \"Up\" if direction == 1 else \"Down\"\n",
    "    print(\n",
    "        f\"Time: {timestamp}, Direction: {direction_str}, Predicted Price: {price:.2f} ({low:.2f} - {high:.2f})\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
