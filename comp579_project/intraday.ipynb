{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import ta\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from stable_baselines3 import PPO, A2C, DDPG, SAC, TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\john\\.cache\\kagglehub\\datasets\\gratefuldata\\intraday-stock-data-1-min-sp-500-200821\\versions\\1\n",
      "\n",
      "Files in S&P 500 dataset directory:\n",
      "['1_min_SPY_2008-2021.csv']\n",
      "Files saved to ./datasets/sp500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>barCount</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20090522  07:30:00</td>\n",
       "      <td>89.45</td>\n",
       "      <td>89.46</td>\n",
       "      <td>89.37</td>\n",
       "      <td>89.37</td>\n",
       "      <td>7872</td>\n",
       "      <td>2102</td>\n",
       "      <td>89.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20090522  07:31:00</td>\n",
       "      <td>89.38</td>\n",
       "      <td>89.53</td>\n",
       "      <td>89.37</td>\n",
       "      <td>89.50</td>\n",
       "      <td>5336</td>\n",
       "      <td>1938</td>\n",
       "      <td>89.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20090522  07:32:00</td>\n",
       "      <td>89.51</td>\n",
       "      <td>89.54</td>\n",
       "      <td>89.48</td>\n",
       "      <td>89.49</td>\n",
       "      <td>3349</td>\n",
       "      <td>1184</td>\n",
       "      <td>89.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20090522  07:33:00</td>\n",
       "      <td>89.49</td>\n",
       "      <td>89.49</td>\n",
       "      <td>89.31</td>\n",
       "      <td>89.34</td>\n",
       "      <td>3495</td>\n",
       "      <td>1240</td>\n",
       "      <td>89.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20090522  07:34:00</td>\n",
       "      <td>89.33</td>\n",
       "      <td>89.46</td>\n",
       "      <td>89.33</td>\n",
       "      <td>89.39</td>\n",
       "      <td>9731</td>\n",
       "      <td>2637</td>\n",
       "      <td>89.379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                date   open   high    low  close  volume  \\\n",
       "0           0  20090522  07:30:00  89.45  89.46  89.37  89.37    7872   \n",
       "1           1  20090522  07:31:00  89.38  89.53  89.37  89.50    5336   \n",
       "2           2  20090522  07:32:00  89.51  89.54  89.48  89.49    3349   \n",
       "3           3  20090522  07:33:00  89.49  89.49  89.31  89.34    3495   \n",
       "4           4  20090522  07:34:00  89.33  89.46  89.33  89.39    9731   \n",
       "\n",
       "   barCount  average  \n",
       "0      2102   89.424  \n",
       "1      1938   89.468  \n",
       "2      1184   89.516  \n",
       "3      1240   89.386  \n",
       "4      2637   89.379  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download latest version\n",
    "# path = kagglehub.dataset_download(\"debashis74017/algo-trading-data-nifty-100-data-with-indicators\")\n",
    "path_sp500 = kagglehub.dataset_download(\n",
    "    \"gratefuldata/intraday-stock-data-1-min-sp-500-200821\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Path to dataset files:\", path_sp500)\n",
    "\n",
    "print(\"\\nFiles in S&P 500 dataset directory:\")\n",
    "try:\n",
    "    files_sp500 = os.listdir(path_sp500)\n",
    "    print(files_sp500)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Directory not found at {path_sp500}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "local_dir = \"./datasets/sp500\"\n",
    "os.makedirs(local_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for fname in files_sp500:\n",
    "    src = os.path.join(path_sp500, fname)\n",
    "    dst = os.path.join(local_dir, fname)\n",
    "    shutil.copy2(src, dst)  # Use copy2 to preserve metadata\n",
    "\n",
    "print(f\"Files saved to {local_dir}\")\n",
    "\n",
    "\n",
    "full_csv_path = os.path.join(path_sp500, files_sp500[0])\n",
    "\n",
    "df = pd.read_csv(full_csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"sp500_with_ta_features.csv\"\n",
    "if os.path.exists(output_path):\n",
    "    df = pd.read_csv(output_path)\n",
    "    # Ensure datetime column is correctly parsed when loading from CSV\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "else:\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    start_date = pd.Timestamp(\"2018-01-01\")\n",
    "    end_date = pd.Timestamp(\"2021-12-31 23:59:59\")\n",
    "    df = df[(df[\"datetime\"] >= start_date) & (df[\"datetime\"] <= end_date)]\n",
    "    df = df.sort_values(\"datetime\")\n",
    "\n",
    "    df = ta.add_all_ta_features(\n",
    "        df,\n",
    "        open=\"open\",\n",
    "        high=\"high\",\n",
    "        low=\"low\",\n",
    "        close=\"close\",\n",
    "        volume=\"volume\",\n",
    "        fillna=True,\n",
    "    )\n",
    "\n",
    "    df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset date range:\n",
      "Earliest date: 2018-01-02 09:30:00\n",
      "Latest date: 2021-05-06 13:59:00\n",
      "Total unique dates: 842\n",
      "\n",
      "Data points per year:\n",
      "datetime\n",
      "2018     97290\n",
      "2019     97020\n",
      "2020    133809\n",
      "2021     37566\n",
      "Name: count, dtype: int64\n",
      "     Unnamed: 0                date    open    high     low   close  volume  \\\n",
      "120     1605521  20180102  09:30:00  268.17  268.18  268.15  268.18     369   \n",
      "121     1605522  20180102  09:31:00  268.17  268.18  268.12  268.13     306   \n",
      "122     1605523  20180102  09:32:00  268.13  268.14  268.11  268.11     881   \n",
      "123     1605524  20180102  09:33:00  268.11  268.12  268.10  268.10    1070   \n",
      "124     1605525  20180102  09:34:00  268.10  268.14  268.10  268.14     745   \n",
      "\n",
      "     barCount  average            datetime  ...  momentum_pvo_hist  \\\n",
      "120       192  268.162 2018-01-02 09:30:00  ...          -2.351737   \n",
      "121       148  268.148 2018-01-02 09:31:00  ...          -5.726195   \n",
      "122       345  268.121 2018-01-02 09:32:00  ...          -3.018600   \n",
      "123       254  268.107 2018-01-02 09:33:00  ...           0.367072   \n",
      "124       368  268.113 2018-01-02 09:34:00  ...           0.016454   \n",
      "\n",
      "     momentum_kama  others_dr  others_dlr  others_cr  hour  minute  \\\n",
      "120     268.229219   0.007458    0.007458   0.168080     9      30   \n",
      "121     268.222239  -0.018644   -0.018646   0.149404     9      31   \n",
      "122     268.216367  -0.007459   -0.007459   0.141934     9      32   \n",
      "123     268.210278  -0.003730   -0.003730   0.138199     9      33   \n",
      "124     268.207290   0.014920    0.014919   0.153139     9      34   \n",
      "\n",
      "     volume_norm  volume_obv_norm  volume_vwap_norm  \n",
      "120     0.003788         0.000024          0.243729  \n",
      "121     0.003142         0.000023          0.243695  \n",
      "122     0.009045         0.000019          0.243614  \n",
      "123     0.010986         0.000015          0.243525  \n",
      "124     0.007649         0.000018          0.243452  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a filter for Regular Trading Hours (9:30 AM - 4:00 PM ET)\n",
    "df[\"hour\"] = df[\"datetime\"].dt.hour\n",
    "df[\"minute\"] = df[\"datetime\"].dt.minute\n",
    "\n",
    "rth_filter = (\n",
    "    # 9:30 AM to 3:59 PM (handle 9:30 properly)\n",
    "    ((df[\"hour\"] == 9) & (df[\"minute\"] >= 30))  # 9:30-9:59\n",
    "    | ((df[\"hour\"] > 9) & (df[\"hour\"] < 16))  # 10:00-15:59\n",
    "    | ((df[\"hour\"] == 16) & (df[\"minute\"] == 0))  # 4:00 PM exactly\n",
    ")\n",
    "\n",
    "\n",
    "df = df[rth_filter]\n",
    "\n",
    "# Normalize the volume features you want to use\n",
    "volume_features = [\"volume\", \"volume_obv\", \"volume_vwap\"]\n",
    "for feature in volume_features:\n",
    "    scaler = MinMaxScaler()\n",
    "    df[f\"{feature}_norm\"] = scaler.fit_transform(df[[feature]])\n",
    "df[volume_features + [f\"{feat}_norm\" for feat in volume_features]].head()\n",
    "\n",
    "\n",
    "print(f\"Full dataset date range:\")\n",
    "print(f\"Earliest date: {df['datetime'].min()}\")\n",
    "print(f\"Latest date: {df['datetime'].max()}\")\n",
    "print(f\"Total unique dates: {df['datetime'].dt.date.nunique()}\")\n",
    "yearly_counts = df[\"datetime\"].dt.year.value_counts().sort_index()\n",
    "print(\"\\nData points per year:\")\n",
    "print(yearly_counts)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: (365685, 100)\n",
      "Training data (2018): (97290, 100)\n",
      "Validation data (2019): (97020, 100)\n",
      "Test data (2020): (133809, 100)\n",
      "New training data index range: 3825 to 2068868\n",
      "New validation data index range: 4605 to 2064773\n",
      "New test data index range: 3195 to 2067189\n"
     ]
    }
   ],
   "source": [
    "# Define time ranges for data splits\n",
    "training_time_range = (pd.Timestamp(\"2018-01-01\"), pd.Timestamp(\"2018-12-31 23:59:59\"))\n",
    "validation_time_range = (\n",
    "    pd.Timestamp(\"2019-01-01\"),\n",
    "    pd.Timestamp(\"2019-12-31 23:59:59\"),\n",
    ")\n",
    "test_time_range = (pd.Timestamp(\"2020-01-01\"), pd.Timestamp(\"2020-12-31 23:59:59\"))\n",
    "\n",
    "# Make sure datetime column is in datetime format\n",
    "if not pd.api.types.is_datetime64_any_dtype(df[\"datetime\"]):\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "# Split the DataFrame using boolean filtering\n",
    "training_df = df[\n",
    "    (df[\"datetime\"] >= training_time_range[0])\n",
    "    & (df[\"datetime\"] <= training_time_range[1])\n",
    "].copy()\n",
    "\n",
    "validation_df = df[\n",
    "    (df[\"datetime\"] >= validation_time_range[0])\n",
    "    & (df[\"datetime\"] <= validation_time_range[1])\n",
    "].copy()\n",
    "\n",
    "test_df = df[\n",
    "    (df[\"datetime\"] >= test_time_range[0]) & (df[\"datetime\"] <= test_time_range[1])\n",
    "].copy()\n",
    "\n",
    "# Display the shapes of the resulting DataFrames\n",
    "print(f\"Original data: {df.shape}\")\n",
    "print(f\"Training data (2018): {training_df.shape}\")\n",
    "print(f\"Validation data (2019): {validation_df.shape}\")\n",
    "print(f\"Test data (2020): {test_df.shape}\")\n",
    "print(\n",
    "    \"New training data index range:\",\n",
    "    training_df.index.min(),\n",
    "    \"to\",\n",
    "    training_df.index.max(),\n",
    ")\n",
    "print(\n",
    "    \"New validation data index range:\",\n",
    "    validation_df.index.min(),\n",
    "    \"to\",\n",
    "    validation_df.index.max(),\n",
    ")\n",
    "print(\"New test data index range:\", test_df.index.min(), \"to\", test_df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trend_macd - This is the main MACD line\n",
    "\n",
    "trend_macd_signal - This is the signal line\n",
    "\n",
    "trend_macd_diff - This is the histogram\n",
    "\n",
    "trend_macd_diff = trend_macd - trend_macd_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, stock_data, transaction_cost_percent=0.005):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "\n",
    "        # Remove any empty DataFrames\n",
    "        self.stock_data = {\n",
    "            ticker: df for ticker, df in stock_data.items() if not df.empty\n",
    "        }\n",
    "        self.tickers = list(self.stock_data.keys())\n",
    "\n",
    "        if not self.tickers:\n",
    "            raise ValueError(\"All provided stock data is empty\")\n",
    "\n",
    "        # Calculate the size of one stock's data\n",
    "        sample_df = next(iter(self.stock_data.values()))\n",
    "        self.n_features = len(sample_df.columns)\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1, high=1, shape=(len(self.tickers),), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Observation space: price data for each stock + balance + shares held + net worth + max net worth + current step\n",
    "        self.obs_shape = self.n_features * len(self.tickers) + 2 + len(self.tickers) + 2\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.obs_shape,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Initialize account balance 1M$\n",
    "        self.initial_balance = 1000000\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.max_net_worth = self.initial_balance\n",
    "        self.shares_held = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_shares_sold = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_sales_value = {ticker: 0 for ticker in self.tickers}\n",
    "\n",
    "        # Set the current step\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Calculate the minimum length of data across all stocks\n",
    "        self.max_steps = max(0, min(len(df) for df in self.stock_data.values()) - 1)\n",
    "\n",
    "        # Transaction cost\n",
    "        self.transaction_cost_percent = transaction_cost_percent\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.max_net_worth = self.initial_balance\n",
    "        self.shares_held = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_shares_sold = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_sales_value = {ticker: 0 for ticker in self.tickers}\n",
    "        self.current_step = 0\n",
    "        return self._next_observation(), {}\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # initialize the frame\n",
    "        frame = np.zeros(self.obs_shape)\n",
    "\n",
    "        # Add stock data for each ticker\n",
    "        idx = 0\n",
    "        # Loop through each ticker\n",
    "        for ticker in self.tickers:\n",
    "            # Get the DataFrame for the current ticker\n",
    "            df = self.stock_data[ticker]\n",
    "            # If the current step is less than the length of the DataFrame, add the price data for the current step\n",
    "            if self.current_step < len(df):\n",
    "                frame[idx : idx + self.n_features] = df.iloc[self.current_step].values\n",
    "            # Otherwise, add the last price data available\n",
    "            elif len(df) > 0:\n",
    "                frame[idx : idx + self.n_features] = df.iloc[-1].values\n",
    "            # Move the index to the next ticker\n",
    "            idx += self.n_features\n",
    "\n",
    "        # Add balance, shares held, net worth, max net worth, and current step\n",
    "        frame[-4 - len(self.tickers)] = self.balance  # Balance\n",
    "        frame[-3 - len(self.tickers) : -3] = [\n",
    "            self.shares_held[ticker] for ticker in self.tickers\n",
    "        ]  # Shares held\n",
    "        frame[-3] = self.net_worth  # Net worth\n",
    "        frame[-2] = self.max_net_worth  # Max net worth\n",
    "        frame[-1] = self.current_step  # Current step\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def step(self, actions):\n",
    "        # update the current step\n",
    "        self.current_step += 1\n",
    "\n",
    "        # check if we have reached the maximum number of steps\n",
    "        if self.current_step > self.max_steps:\n",
    "            return self._next_observation(), 0, True, False, {}\n",
    "\n",
    "        current_prices = {}\n",
    "        # Loop through each ticker and perform the action\n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            # Get the current price of the stock\n",
    "            current_prices[ticker] = self.stock_data[ticker].iloc[self.current_step][\n",
    "                \"Close\"\n",
    "            ]\n",
    "            # get the action for the current ticker\n",
    "            action = actions[i]\n",
    "\n",
    "            if action > 0:  # Buy\n",
    "                # Calculate the number of shares to buy\n",
    "                shares_to_buy = int(self.balance * action / current_prices[ticker])\n",
    "                # Calculate the cost of the shares\n",
    "                cost = shares_to_buy * current_prices[ticker]\n",
    "                # Transaction cost\n",
    "                transaction_cost = cost * self.transaction_cost_percent\n",
    "                # Update the balance and shares held\n",
    "                self.balance -= cost + transaction_cost\n",
    "                # Update the total shares sold\n",
    "                self.shares_held[ticker] += shares_to_buy\n",
    "\n",
    "            elif action < 0:  # Sell\n",
    "                # Calculate the number of shares to sell\n",
    "                shares_to_sell = int(self.shares_held[ticker] * abs(action))\n",
    "                # Calculate the sale value\n",
    "                sale = shares_to_sell * current_prices[ticker]\n",
    "                # Transaction cost, fixed fees...\n",
    "                transaction_cost = sale * self.transaction_cost_percent\n",
    "                # Update the balance and shares held\n",
    "                self.balance += sale - transaction_cost\n",
    "                # Update the total shares sold\n",
    "                self.shares_held[ticker] -= shares_to_sell\n",
    "                # Update the shares sold\n",
    "                self.total_shares_sold[ticker] += shares_to_sell\n",
    "                # Update the total sales value\n",
    "                self.total_sales_value[ticker] += sale\n",
    "\n",
    "        # Calculate the net worth\n",
    "        self.net_worth = self.balance + sum(\n",
    "            self.shares_held[ticker] * current_prices[ticker] for ticker in self.tickers\n",
    "        )\n",
    "        # Update the max net worth\n",
    "        self.max_net_worth = max(self.net_worth, self.max_net_worth)\n",
    "        # Calculate the reward\n",
    "        reward = self.net_worth - self.initial_balance\n",
    "        # Check if the episode is done\n",
    "        done = self.net_worth <= 0 or self.current_step >= self.max_steps\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        # Print the current step, balance, shares held, net worth, and profit\n",
    "        profit = self.net_worth - self.initial_balance\n",
    "        print(f\"Step: {self.current_step}\")\n",
    "        print(f\"Balance: {self.balance:.2f}\")\n",
    "        for ticker in self.tickers:\n",
    "            print(f\"{ticker} Shares held: {self.shares_held[ticker]}\")\n",
    "        print(f\"Net worth: {self.net_worth:.2f}\")\n",
    "        print(f\"Profit: {profit:.2f}\")\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def update_stock_data(self, new_stock_data, transaction_cost_percent=None):\n",
    "    \"\"\"\n",
    "    Update the environment with new stock data.\n",
    "\n",
    "    Parameters:\n",
    "    new_stock_data (dict): Dictionary containing new stock data,\n",
    "                           with keys as stock tickers and values as DataFrames.\n",
    "    \"\"\"\n",
    "    # Remove empty DataFrames\n",
    "    self.stock_data = {\n",
    "        ticker: df for ticker, df in new_stock_data.items() if not df.empty\n",
    "    }\n",
    "    self.tickers = list(self.stock_data.keys())\n",
    "\n",
    "    if not self.tickers:\n",
    "        raise ValueError(\"All new stock data are empty\")\n",
    "\n",
    "    # Update the number of features if needed\n",
    "    sample_df = next(iter(self.stock_data.values()))\n",
    "    self.n_features = len(sample_df.columns)\n",
    "\n",
    "    # Update observation space\n",
    "    self.obs_shape = self.n_features * len(self.tickers) + 2 + len(self.tickers) + 2\n",
    "    self.observation_space = spaces.Box(\n",
    "        low=-np.inf, high=np.inf, shape=(self.obs_shape,), dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Update maximum steps\n",
    "    self.max_steps = max(0, min(len(df) for df in self.stock_data.values()) - 1)\n",
    "\n",
    "    # Update transaction cost if provided\n",
    "    if transaction_cost_percent is not None:\n",
    "        self.transaction_cost_percent = transaction_cost_percent\n",
    "\n",
    "    # Reset the environment\n",
    "    self.reset()\n",
    "\n",
    "    print(f\"The environment has been updated with {len(self.tickers)} new stocks.\")\n",
    "\n",
    "\n",
    "# Define SAC Agent\n",
    "class SACAgent:\n",
    "    def __init__(self, env, total_timesteps):\n",
    "        self.model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "    def train(self, total_timesteps):\n",
    "        self.model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "    def predict(self, obs):\n",
    "        action, _ = self.model.predict(obs)\n",
    "        return action\n",
    "\n",
    "\n",
    "def test_agent(env, agent, stock_data, n_tests=1000, visualize=False):\n",
    "    \"\"\"\n",
    "    Test a single agent and track performance metrics, with an option to visualize the results.\n",
    "\n",
    "    Parameters:\n",
    "    - env: The trading environment.\n",
    "    - agent: The agent to be tested.\n",
    "    - stock_data: Data for the stocks in the environment.\n",
    "    - n_tests: Number of tests to run (default: 1000).\n",
    "    - visualize: Boolean flag to enable or disable visualization (default: False).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing steps, balances, net worths, and shares held.\n",
    "    \"\"\"\n",
    "    # Initialize metrics tracking\n",
    "    metrics = {\n",
    "        \"steps\": [],\n",
    "        \"balances\": [],\n",
    "        \"net_worths\": [],\n",
    "        \"shares_held\": {ticker: [] for ticker in stock_data.keys()},\n",
    "    }\n",
    "\n",
    "    # Reset the environment before starting the tests\n",
    "    obs = env.reset()\n",
    "\n",
    "    # If you have 3 tickers, action will be something like [0.2, -0.5, 0.0]\n",
    "    for i in range(n_tests):\n",
    "        metrics[\"steps\"].append(i)\n",
    "        action = agent.predict(obs)\n",
    "        obs, rewards, dones, infos = env.step(action)\n",
    "        if visualize:\n",
    "            env.render()\n",
    "\n",
    "        # Track metrics\n",
    "        metrics[\"balances\"].append(env.get_attr(\"balance\")[0])\n",
    "        metrics[\"net_worths\"].append(env.get_attr(\"net_worth\")[0])\n",
    "        env_shares_held = env.get_attr(\"shares_held\")[0]\n",
    "\n",
    "        # Update shares held for each ticker\n",
    "        for ticker in stock_data.keys():\n",
    "            if ticker in env_shares_held:\n",
    "                metrics[\"shares_held\"][ticker].append(env_shares_held[ticker])\n",
    "            else:\n",
    "                metrics[\"shares_held\"][ticker].append(\n",
    "                    0\n",
    "                )  # Append 0 if ticker is not found\n",
    "\n",
    "        if dones:\n",
    "            obs = env.reset()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# function to visualize the multiple portfolio net worths ( same chart )\n",
    "def visualize_multiple_portfolio_net_worth(steps, net_worths_list, labels):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, net_worths in enumerate(net_worths_list):\n",
    "        plt.plot(steps, net_worths, label=labels[i])\n",
    "    plt.title(\"Net Worth Over Time\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Net Worth\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_and_visualize_agents(env, agents, training_data, n_tests=1000):\n",
    "    metrics = {}\n",
    "    for agent_name, agent in agents.items():\n",
    "        print(f\"Testing {agent_name}...\")\n",
    "        metrics[agent_name] = test_agent(\n",
    "            env, agent, training_data, n_tests=n_tests, visualize=True\n",
    "        )\n",
    "        print(f\"Done testing {agent_name}!\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"All agents tested!\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Extract net worths for visualization\n",
    "    net_worths = [metrics[agent_name][\"net_worths\"] for agent_name in agents.keys()]\n",
    "    steps = next(iter(metrics.values()))[\n",
    "        \"steps\"\n",
    "    ]  # Assuming all agents have the same step count for simplicity\n",
    "\n",
    "    # Visualize the performance metrics of multiple agents\n",
    "    visualize_multiple_portfolio_net_worth(steps, net_worths, list(agents.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '20180102  09:30:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: StockTradingEnv(stock_data)])\n\u001b[0;32m      5\u001b[0m sac_agent \u001b[38;5;241m=\u001b[39m SACAgent(env, total_timesteps)\n\u001b[1;32m----> 6\u001b[0m \u001b[43msac_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Test the agent\u001b[39;00m\n\u001b[0;32m      9\u001b[0m metrics \u001b[38;5;241m=\u001b[39m test_agent(env, sac_agent, stock_data, n_tests\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 210\u001b[0m, in \u001b[0;36mSACAgent.train\u001b[1;34m(self, total_timesteps)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, total_timesteps):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[0;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:314\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[0;32m    307\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m--> 314\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must set the environment before calling learn()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:297\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, VectorizedActionNoise)\n\u001b[0;32m    294\u001b[0m ):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;241m=\u001b[39m VectorizedActionNoise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:424\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\john\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:78\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m     77\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m---> 78\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_seeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmaybe_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 58\u001b[0m, in \u001b[0;36mStockTradingEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_sales_value \u001b[38;5;241m=\u001b[39m {ticker: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtickers}\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "Cell \u001b[1;32mIn[10], line 72\u001b[0m, in \u001b[0;36mStockTradingEnv._next_observation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# If the current step is less than the length of the DataFrame, add the price data for the current step\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(df):\n\u001b[1;32m---> 72\u001b[0m     \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Otherwise, add the last price data available\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '20180102  09:30:00'"
     ]
    }
   ],
   "source": [
    "# Train SAC Agent\n",
    "stock_data = {\"spy\": df}\n",
    "total_timesteps = 10000\n",
    "env = DummyVecEnv([lambda: StockTradingEnv(stock_data)])\n",
    "sac_agent = SACAgent(env, total_timesteps)\n",
    "sac_agent.train(total_timesteps)\n",
    "\n",
    "# Test the agent\n",
    "metrics = test_agent(env, sac_agent, stock_data, n_tests=1000, visualize=True)\n",
    "\n",
    "# Visualize the performance metrics of the agent\n",
    "visualize_multiple_portfolio_net_worth(\n",
    "    metrics[\"steps\"], [metrics[\"net_worths\"]], [\"SAC Agent\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
